{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <p style=\"text-align: right;\"> &#9989; SKylar Milne</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CMSE 202 Final (Section 004 - Spring 2024)\n",
    "\n",
    "The goal of this final is to give you the opportunity to test out some of the skills that you've developed having now finished CMSE 202. In particular, you'll be committing and pushing repository changes to a GitHub repository, working with data to build a network graph, performing regression analysis, and classifying data using a machine learning classifier. You should find that you have all of the skills necessary to complete this exam having completed the second half of CMSE 202!\n",
    "\n",
    "You are encouraged to look through the entire exam before you get started so that you can appropriately budget your time and understand the broad goals of the exam. Once you've read through it, you'll probably want to make sure you do Part 1 first to ensure that your GitHub repository is working correctly. Let your instructor know right away if you run into issues!\n",
    "\n",
    "The exam is set up so that even if you get stuck on one part there are opportunities to get points on the other parts, so consider jumping ahead if you feel like you aren't making progress and then come back later if you have time.\n",
    "\n",
    "**Important note about using online resources**: This exam is \"open internet\". That means that you can look up documentation, google how to accomplish certain Python tasks, etc. Being able to effectively use the internet for computational modeling and data science is a very important skill, so we want to make sure you have the opportunity to exercise that skill. You can also use _your version_ of past CMSE 202 assignments and the CMSE 202 course materials as a resource! **However: The use of any person-to-person communication software or generative AI tools is absolutely not acceptable.** If you are seen accessing your email, using a collaborative cloud storage or document software (e.g. Slack, Google Documents), or generative AIs (e.g. ChatGPT), you will be at risk for receiving a zero on the exam.\n",
    "\n",
    "**Keep your eyes on your screen!** Unfortunately, there isn't enough space in the room for everyone to sit at their own table so please do your best to keep your eyes on your own screen. This exam is designed to give *you* the opportunity to show the instructor what you can do and you should hold yourself accountable for maintaining a high level of academic integrity. If any of the instructors observe suspicious behavior, you will, again, risk receiving a zero. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 0: Academic integrity statement\n",
    "\n",
    "Read the following statement and edit the markdown text to put your name in the statement. This is your commitment to doing your own authentic work on this exam."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> I, **Skylar Milne**, affirm that this exam represents my own authetic work, without the use of any unpermitted aids or resources or person-to-person communication. I understand that this exam an an opportunity to showcase my own progress in developing and improving my computational skills and have done my best to demonstrate those skills."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 1: Add to your Git repository to track your progress on your exam (4 points)\n",
    "\n",
    "Before you get to far along in the exam, you're going to add it to the `cmse202-s24-turnin` repository you created in class so that you can track your progress on the exam and preserve the final version that you turn in. **Make sure to pull your most recent respository before beginning**. In order to do this you need to\n",
    "\n",
    "**&#9989; Do the following**:\n",
    "\n",
    "1. Navigate to your `cmse202-s24-turnin` repository and create a new directory called `final`.\n",
    "2. Move this notebook into that **new directory** in your repository, then **add it and commit it to your repository**.\n",
    "1. Finally, to test that everything is working, \"git push\" the file so that it ends up in your GitHub repository.\n",
    "\n",
    "**Important**: Double check you've added your Professor and your TA as collaborators to your \"turnin\" respository (you should have done this in the previous homework assignment).\n",
    "\n",
    "**Also important**: Make sure that the version of this notebook that you are working on is the same one that you just added to your repository! If you are working on a different copy of the noteobok, **none of your changes will be tracked**!\n",
    "\n",
    "If everything went as intended, the file should now show up on your GitHub account in the \"`cmse202-s24-turnin`\" repository inside the `final` directory that you just created. Periodically, **you'll be asked to commit your changes to the repository and push them to the remote GitHub location**. Of course, you can always commit your changes more often than that, if you wish.  It can be good to get into a habit of committing your changes any time you make a significant modification, or when you stop working on the project for a bit.\n",
    "\n",
    "&#9989; **Do this**: Before you move on, put the command that your instructor should run to clone your repository in the markdown cell below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` bash\n",
    "git clone https://github.com/milneskylar/CMSE202-f23-turnin/tree/main/final\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 2: Generate a network graph from data (16 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part of the exam, we will look at Facebook groups in Tennessee. Some of these groups are very connected (share members with many groups), while others are not very connected (share members with few other groups). We will model these group connections as an undirected graph. Every node will be a Facebook group and there will be an edge between two groups if they share at least one member. The dataset originally comes from [here](https://www.kaggle.com/datasets/stkbailey/nashville-meetup?select=group-edges.csv)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **Question 2.1 (3 points)**: To get started, **download the `.csv` file and place it in the same directory as your notebook**, then **read in the `FacebookGroupNetwork.csv` dataset** and finally **display the first few rows of the data**. You can use **Pandas** for this task or any other Python tool you prefer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group1</th>\n",
       "      <th>group2</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nashville CocoaHeads</td>\n",
       "      <td>Nash.rb</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nashville CocoaHeads</td>\n",
       "      <td>Nashville Christian Technologists and Entrepre...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nashville CocoaHeads</td>\n",
       "      <td>Stepping Out Social Dance Meetup</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nashville CocoaHeads</td>\n",
       "      <td>NashReact</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nashville CocoaHeads</td>\n",
       "      <td>WordPress Nashville</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 group1                                             group2  \\\n",
       "0  Nashville CocoaHeads                                            Nash.rb   \n",
       "1  Nashville CocoaHeads  Nashville Christian Technologists and Entrepre...   \n",
       "2  Nashville CocoaHeads                   Stepping Out Social Dance Meetup   \n",
       "3  Nashville CocoaHeads                                          NashReact   \n",
       "4  Nashville CocoaHeads                                WordPress Nashville   \n",
       "\n",
       "   weight  \n",
       "0       2  \n",
       "1       1  \n",
       "2       1  \n",
       "3       2  \n",
       "4       1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Put your code here\n",
    "import pandas as pd\n",
    "facebook = pd.read_csv('FacebookGroupNetwork.csv')\n",
    "facebook.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should see three columns: `group1`, `group2`, and `weight`. We are going to ignore `weight` in this exam (it is the number of members shared between groups). `group1` and `group2` are the two (unique) group names that share some number of members. We will now create a `networkx` graph using this dataset.\n",
    "\n",
    "&#9989; **Question 2.2 (4 points)**: **Create an undirected `networkx` graph** (you can call it `G`). Make sure it is an undirected graph. Then, iterate over the dataset and **add edges between the `group1` and `group2` groups** on each line. Ignore the weights. (The resulting graph should now have an edge per entry in the dataset and the set of all group names should be the set of all nodes.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Put your code here\n",
    "import networkx as nx\n",
    "G = nx.Graph()\n",
    "\n",
    "for i in facebook['group1']:\n",
    "    G.add_node(i)\n",
    "for j in facebook['group2']:\n",
    "    G.add_node(j)\n",
    "for i in facebook['group1']:\n",
    "    for j in facebook['group2']:\n",
    "        G.add_edge(i,j)\n",
    "\n",
    "G.edges()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now visualize the graph.\n",
    "\n",
    "&#9989; **Question 2.3 (5 points)**: Create a large figure for drawing the graph using something like `plt.figure(figsize=(20,20))`. Then, draw the graph using `networkx`. Make sure that when drawing your graph, you accomplish the following:\n",
    "1. The `\"Data Science Nashville\"` node should be colored red (it may be hard to see since this will appear in the middle since it is a highly connected group).\n",
    "2. The group `\"Nashville Squash Meetup\"` should be colored blue (this will appear at the edge with only one connection).\n",
    "3. All of the other groups should have a third, different color.\n",
    "\n",
    "To recap, you should have **three** different colors in your graph, one for `\"Data Science Nashville\"`, one for `\"Nashville Squash Meetup\"`, and one for all of the other groups.\n",
    "\n",
    "(Partial credit if you generate the graph but the colors are not set as described.)\n",
    "\n",
    "**Note**: this will be a very crowded graph because it's a complex, heavily-interconnected network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Put your code here\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(20,20))\n",
    "\n",
    "color_map = []\n",
    "for node in G:\n",
    "    if node == 'Data Science Nashville':\n",
    "        color_map.append('red')\n",
    "    elif node == 'Nashville Squash Meetup':\n",
    "        color_map.append('blue')\n",
    "    else: \n",
    "        color_map.append('green')  \n",
    "nx.draw(G, node_color=color_map, with_labels=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, using **only the graph you created (not the initial row-based data)**, answer the following questions.\n",
    "\n",
    "You may find it useful to review the \"Methods\" section of the [networkx Graph documentation](https://networkx.org/documentation/stable/reference/classes/graph.html#methods).\n",
    "\n",
    "&#9989; **Question 2.4 (1 point)** What is the total number of groups?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Put your code here\n",
    "G.number_of_nodes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **Question 2.5 (1 point)** With how many connections does `\"Code for Nashville\"` have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Put your code here\n",
    "G.size('Code for Nashville')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **Question 2.6 (1 point)** True or False?: `\"Nashville Online Entrepreneurs\"` has a connection with `\"Nashville Tennis Lessons\"`. Use a graph method to determine this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Put your code here\n",
    "G.number_of_edges('Nashville Online Entrepreneurs', 'Nashville Tennis Lessons')\n",
    "\n",
    "#FALSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **Question 2.7 (1 point)** Using the relevant `networkx` function (consult the documentation/internet resources), **find the \"shortest path\" between `\"All Things German Book Club\"` and `\"Data Science Nashville\"`**. The two groups are not directly connected, but you should be able to determine a set of nodes to \"traverse\" to get from one group to the other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Put your code here\n",
    "\n",
    "nx.bidirectional_shortest_path(G, \"All Things German Book Club\", \"Data Science Nashville\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### &#128721; STOP\n",
    "**Pause to commit your changes to your Git repository!**\n",
    "Take a moment to save your notebook, commit the changes to your Git repository using the commit message \"**Committing Part 2**\", and push the changes to GitHub.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 3: Perform a regression analysis on data (16 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now be looking at a dataset of housing prices in Boston. \n",
    "\n",
    "&#9989; **Question 3.1 (2 points)**: To get started, **download the `BostonHousing.csv` file and place it in the same directory as your notebook**, then **read in the `BostonHousing.csv` dataset** and finally **display the first few rows of the data**. You can use **Pandas** for this task or any other Python tool you prefer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Put your code here\n",
    "boston = pd.read_csv('BostonHousing.csv')\n",
    "boston.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should see a list of house median values with several different pieces of information about them, such as the crime rate, age, property tax rate, etc.\n",
    "\n",
    "You will be trying to predict `medv` (median value) using linear regression using a subset of the other features.\n",
    "\n",
    "&#9989; **Question 3.2 (3 points)**: Create two arrays and/or dataframes from the data you just loaded, one of them called `y`, the other one called `X`. `y` should **only** include the `medv` column, while `X` should include **all the remaining columns**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Put your code here\n",
    "y = boston['medv']\n",
    "drop = boston.drop(columns = 'medv')\n",
    "X = drop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the labels and features to fit, we will use the `statsmodels` `OLS` model to fit it. \n",
    "\n",
    "&#9989; **Question 3.3 (2 point)**: Before we do this, **add a column of constants (set to 1.0) to the `X`**. There is a `statsmodel` function you saw in class that allows you to do that. Call this new data structure `X_const`. (If you cannot figure this out, you can use `X` instead of `X_const` for the next questions.) Display the first 5 rows of `X_const` to make sure the new column exists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Put your code here\n",
    "import statsmodels.api as sm\n",
    "X_const = sm.add_constant(X)\n",
    "X_const.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you will perform the actual fit.\n",
    "\n",
    "&#9989; **Question 3.4 (3 points)**: Using `statsmodels` `OLS`, perform a fit using `y` (containing `medv`) as the quantity to fit (y) and fit it to the `X_const` (X). Once the fit is done print the fit `summary()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Put your code here\n",
    "model = sm.OLS(y,X)\n",
    "results = model.fit()\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **Question 3.5 (2 points)**: Which 2 features would you say contributes the least to the fit result and/or is the least significant? Make sure to justify your answer with a sentence or two. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=+3>&#9998;</font> The two features that contribut the least would be age and indus since their P values are much, much higher than 0.005, and I chose those two that are high because they have the largest/highest numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **Question 3.6 (2 points)**: Now **run the fit again, but with the \"least important\" features you identified in Q3.5 removed**. Make sure your new features still include the `constant` column (unless that happens to be one of the least important features). **Print the fit `summary()`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Put your code here\n",
    "boston_2 = boston.drop(columns = ['indus', 'age'])\n",
    "X_2 = boston_2\n",
    "X_const_2 = sm.add_constant(X_2)\n",
    "model_2 = sm.OLS(y,X_2)\n",
    "results_2 = model_2.fit()\n",
    "print(results_2.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **Question 3.7 (2 points)**: Comment on the difference in fit quality between the two fits you just performed. Is one much better or worse than the other? Is the difference what you expected? Explain how you judged the quality given the fit statistics you printed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=+3>&#9998;</font> The The R sqared value is much better, actually it is 1.000 with those two columns dropped. I was not expecting the 1.000, though I was expecting a better R squared value, so this is good. THis better valeu means that the fit without thise two columns is perfect, so it is technically much better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### &#128721; STOP\n",
    "**Pause to commit your changes to your Git repository!**\n",
    "\n",
    "Take a moment to save your notebook, commit the changes to your Git repository using the commit message \"**Committing Part 3**\", and push the changes to GitHub.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 4: Perform a support vector machine (SVM) classification on data (16 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this part of the exam, you will be using a dataset that records metrics about songs and the goal is to predict the genre of the song. \n",
    "\n",
    "&#9989; **Question 4.1 (1 point)**: To get started, **download the `music_genre_classifier.csv` file and place it in the same directory as your notebook**, then **read in the `music_genre_classifier.csv` dataset** and finally **display the first few rows of the data**. You can use **Pandas** for this task or any other Python tool you prefer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Put your code here\n",
    "music = pd.read_csv('music_genre_classifier.csv')\n",
    "music.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now try to perform **classification**. We will try to see if we can classify the genre using the metrics that are given. We will need perform a train-test split on the data first.\n",
    "\n",
    "&#9989; **Question 4.2 (3 points)**: **Create two data structures** (e.g. dataframes) from your table: one called `labels` containing **only** the values from the `music_genre` column and one called `features` containing **everything but** the `music_genre` column.\n",
    "\n",
    "Then, perform a **train-test-split** using functions we used in class. Use a `train_size` of `0.75` and `random_state` of `10`. You should now have a training and a testing set with \"labels\" and \"features\" each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Put your code here\n",
    "from sklearn.model_selection import train_test_split\n",
    "labels = music['music_genre']\n",
    "features = music.drop(columns = 'music_genre')\n",
    "\n",
    "features_train, features_test, labels_train, labels_test = train_test_split(features, labels, test_size=0.25, random_state=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **Question 4.3 (6 points)**: **Fit an SVM classifier (using the `sklearn` `SVC` class) to the dataset.** Use a `linear` kernel and set the hyper-parameter `C=1.0`. Then **fit your *training* set** and use the resulting fit to **predict your the *testing* set** so you get predicted labels for the testing set. Finally, print the fit statistics using `confusion_matrix` and `classification_report` (if you prefer the visual plot version of the confusion matrix, you can use `ConfusionMatrixDisplay` from `sklearn.metrics` instead)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Put your code here\n",
    "from sklearn import svm\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "clf = svm.SVC()\n",
    "clf.fit(features_train, labels_train)\n",
    "\n",
    "\n",
    "pred_labels = clf.predict(predict_vectors)\n",
    "predict_vectors = features_test\n",
    "true_labels = labels_test\n",
    "\n",
    "print(classification_report(true_labels, pred_labels, zero_division=0))\n",
    "\n",
    "ConfusionMatrixDisplay.from_estimator(clf, features_test, labels_test);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **Question 4.4 (3 points)**: Interpret the output of your classification report and the confusion matrix by answering these three questions (provide at least 1 or 2 sentences each for full credit): \n",
    "* Explain in a few sentences what you observe in the confusion matrix. \n",
    "* Would you consider this a good or a bad classifier?\n",
    "* Which quantity from the classification report did you use to make this judgement?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=+3>&#9998;</font> \n",
    "\n",
    "- What I observeis that there are mostly true posotovesand negatives from that center line, with comparivetly few (execpt for a few points) false positives and negatives on the right and left side so fthe graph, respectively.\n",
    "- I would consider this an okay qualifier, as there are still too many falses to make it completely trustworthy.\n",
    "- I used the fact that only one point haev over 200 true positives and that there are a few falses that have over 80 (or even just 30) counts in them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **Question 4.5 (3 points)**: We have been using machine learning \"jargon\" in this section and in class. In a few sentences each explain the following concepts:\n",
    "* What are \"labels\" and \"features\"?\n",
    "* Why do we need \"training sets\" and \"testing sets\"?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=+3>&#9998;</font> \n",
    "\n",
    "- labels are the desired outcome that we wish for, fetaures are the characteristics that brign us there and make these predictions. \n",
    "- we need training to make the machine know what it is meant to do as well as learn so that when it is tested, it will be accurate enough to be able to be used in the future for other sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### &#128721; STOP\n",
    "**Pause to commit your changes to your Git repository!**\n",
    "\n",
    "Take a moment to save your notebook, commit the changes to your Git repository using the commit message \"**Committing Part 4**\", and push the changes to GitHub.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## You're done! Congrats on finishing your CMSE 202 Final!\n",
    "\n",
    "Make sure all of your changes to your repository are committed and pushed to GitHub. Also upload a copy of this notebook to the dropbox on D2L in case something went wrong with your repository or if you couldn't get the repository to work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
